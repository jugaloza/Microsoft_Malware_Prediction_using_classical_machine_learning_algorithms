# Microsoft_Malware_Prediction_using_classical_machine_learning_algorithms

This repository contains solution for the topic which I have selected as part of case study using classical machine learning algorithms to solve problem on predicting probability for whether a machine will be soon hit by malware, topic selected from kaggle.

Link :- https://www.kaggle.com/c/microsoft-malware-prediction/overview

# 1. Problem Description:
Malware attacks are one of the rising concerns in terms of security and
integrity of data for the users and organizations using Windows
systems. According to NetMarketShare firm(source Wikipedia), as per
their survey on desktop os market share in September 2019,
Microsoft Windows OS rules the market by 87%, so here comes the
biggest challenge for Microsoft to provide antivirus defender or other
security products which provides accurate and efficient results
whether machine will be infected with malware or not to keep their
data secured and remain non-vulnerable from such kind of attacks.

Main agenda of this problem is to come up with a ML technique 
which can be able to predict the probability for a machine 
to be likely infected from malware.

# 2. Performance metrics:
For checking the performance of model, I had used  area under the ROC curve between the predicted probability and the observed label. And achieved 0.74 AUC score for the best selected model.

# 3. Solution Description:
To solve this problem I had implemented 2 models and compared their performance based on AUC score and selected the best model to be used on test data to predict the  final probabilities. 

 * Model 1 : First I implemented Lightgbm model on train dataset and hypertuned its hyperparameters using optuna library.
 * Model 2: Implemented my own custom stacking models using different classifiers and hypertuned number of base models using gridsearch cv scikit library.
 
 # 4. Data:
 
Dataset can be found from https://www.kaggle.com/c/microsoft-malware-prediction/data which consist of both train dataset with class labels and test dataset

 # 5. Hardware:
  Because of huge dataset for training purpose and computation limitations, deployed my own jupyter server on Google cloud platform with below specs:
  
   * 8 vCPUs
   * 64 GB RAM
   
 # 6. Libraries:
 Below libraries used for solving this problem
  * numpy
  * pandas
  * dask
  * phik (library for finding correlation amongst the features)
  * scipy
  * lightgbm
  * scikit learn library of various classifiers
  * optuna (for hyperparameter tuning)
  * xgboost
  * And many more


